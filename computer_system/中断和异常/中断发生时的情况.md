我们具体研究一次典型中断发生时的运行流程:

## 禁止调度和抢占

首先我们需要了解，当系统处于中断上下文时，是禁止发生调度和抢占的。进程的[thread_info](computer_system/进程/thread_info.md)中有个preempt_count成员变量，其作为一个变量，包含了3个计数器和一个标志位，如下：

| 位     | 描述               | 解释                                      |
| ----- | ---------------- | --------------------------------------- |
| 0~7   | 抢占计数器            | 也可以说是锁占有数                               |
| 8~15  | 软中断计数器           | 记录软中断被禁用次数，0表示可以进行软中断                   |
| 16~27 | 硬中断计数器           | 表示中断处理嵌套次数，irq_enter()增加它，irq_exit()减少它 |
| 28    | PREEMPT_ACTIVE标志 | 表明正在进行内核抢占，设置此标志也禁止了抢占                  |

当进入到中断时，中断处理程序会调用irq_enter()函数禁止抢占和调度。当中断退出时，会通过irq_exit()减少其硬件计数器。我们需要清楚的就是，无论系统处于硬中断还是软中断，调度和抢占都是被禁止的。

```c
void irq_enter(void)
{
	int cpu = smp_processor_id();

	rcu_irq_enter();
	if (idle_cpu(cpu) && !in_interrupt()) {
		/*
		 * Prevent raise_softirq from needlessly waking up ksoftirqd
		 * here, as softirq will be serviced on return from interrupt.
		 */
		local_bh_disable();
		tick_check_idle(cpu);
		_local_bh_enable();
	}

	__irq_enter();
}

/*
 * It is safe to do non-atomic ops on ->hardirq_context,
 * because NMI handlers may not preempt and the ops are
 * always balanced, so the interrupted value of ->hardirq_context
 * will always be restored.
 */
#define __irq_enter()					\
	do {						\
		account_system_vtime(current);		\
		add_preempt_count(HARDIRQ_OFFSET);	\
		trace_hardirq_enter();			\
	} while (0)
```

```c
void irq_exit(void)
{
	account_system_vtime(current);
	trace_hardirq_exit();
	sub_preempt_count(IRQ_EXIT_OFFSET);
	if (!in_interrupt() && local_softirq_pending())
		invoke_softirq();

	rcu_irq_exit();
#ifdef CONFIG_NO_HZ
	/* Make sure that timer wheel updates are propagated */
	if (idle_cpu(smp_processor_id()) && !in_interrupt() && !need_resched())
		tick_nohz_stop_sched_tick(0);
#endif
	preempt_enable_no_resched();
}

/*
 * Exit irq context without processing softirqs:
 */
#define __irq_exit()					\
	do {						\
		trace_hardirq_exit();			\
		account_system_vtime(current);		\
		sub_preempt_count(HARDIRQ_OFFSET);	\
	} while (0)
```


## 中断产生

我们需要先明确一下，中断控制器与CPU相连的三种线:**INTR、数据线、INTA**。

![中断和异常](computer_system/中断和异常/中断和异常.md#中断控制器)


## SMP系统

在SMP系统，也就是多核情况下，外部的中断控制器有可能会于多个CPU相连，这时候当一个中断产生时，中断控制器有两种方式将此中断送到CPU上，分别是**静态分发**和**动态分发**。区别就是静态分发设置了指定中断送往指定的一个或多个CPU上。动态分发则是由中断控制器控制中断应该发往哪个CPU或CPU组。

CPU已经接收到了中断信号以及中断向量号。此时CPU会自动跳转到中断描述符表地址，以中断向量号作为一个偏移量，直接访问中断向量号对应的门描述符。在门描述符中，有个特权级(DPL)，系统会先检查这个位，然后清除EFLAGS的IF标志位(这也说明了发发生中断时实际上CPU是禁止其他可屏蔽中断的)，之后转到描述符中的中断处理程序中。在上一篇文章我们知道，所有的中断门描述符的中断处理程序都被初始化成了interrupt[i]，它是一段汇编代码。
[初始化：](computer_system/中断和异常/中断和异常.md#初始化：)

## 中断和异常发生时CPU自动完成的工作

我们先注意看一下中断描述符表([Gate_Descriptor](computer_system/中断和异常/中断和异常.md#Gate_Descriptor))，里面的每个中断描述符都有一个段选择符和一个偏移量以及一个DPL(特权级)，而偏移量其实就是中断处理程序的入口地址，当中断或异常发生时：

- CPU首先会确定是中断或异常的向量号，然后根据这个向量号作为偏移量，通过读取idtr中保存的中断向量表(IDT)的基地址获取相应的门描述符。并从门描述符中拿出其中的段选择符
- 根据段选择符从GDT中获取这个段的段描述符(为什么只从GDT中获取？因为初始化所有中段描述符时使用的段选择符几乎都是__USER_CS,__KERNEL_CS,TSS，这几个段选择符对应的段描述符都保存在GDT中)。而这几个段描述符中的基地址都是0x00000000，所以偏移量就是中断处理程序入口地址。
- 这时还没有进入到中断处理程序，CPU会先使用CS寄存器的当前特权级(CPL)与中断向量描述符中对应的段描述符的DPL进行比较，如果DPL的值 <= CPL的值，则通过检查，而DPL的值 > CPL的值时，会产生一个"通用保护"异常。这种情况发生的可能性很小，因为在上一篇初始化的文章中也可以看出来，中断初始化所用的段选择符都是__KERNEL_CS，而异常的段选择符几乎也都是__KERNEL_CS，只除了极特殊的几个除外。也就是大多数中断和异常的段选择符DPL都是0，CPL无论是在内核态(CPL = 0)或者是用户态(CPL = 3)，都可以执行这些中断和异常。这里的检查可以理解为检查是否需要切换段。
- 如果是用户程序的异常(非CPU内部产生的异常),只有系统门和系统中断门的DPL是3，其他的异常门的DPL都为0。这样做的好处是避免了用户程序访问陷阱门、中断门和任务门。 (这里可以理解为进入此"门"的权限, 所以只有系统门和系统中断门是程序能够主动进入的, 也就是我们做系统调用走的门)
- 如果以上检查都通过，并且CS寄存器的特权级发生变化(用户态陷入内核)，则CPU会访问此CPU的TSS段(通过tr寄存器)，在TSS段中读取当前进程的SS和ESP到SS和ESP寄存器中，这样就完成了用户态栈到内核态栈的切换。之后把之前的SS寄存器和ESP寄存器的值保存到当前内核栈中。
- 将eflags、CS、EIP、ESP、SS寄存器的值压入内核栈中。这样就保存了返回后需要执行的上下文。
- 最后将刚才获取到的段选择符加载到CS寄存器(CS段切换)，段描述符加载到CS对应的非编程寄存器中，也就是CS寄存器保存的是__KERNEL_CS，CS寄存器的非编程寄存器中保存的是对应的段描述符。而根据段描述符中的段基址+段内偏移量(保存在门描述符中)，则得到了处理程序入口地址，实际上我们知道段基址是0x00000000，段内偏移量实际上就是处理程序入口地址，这个门描述符的段内偏移量会被放到IP寄存器中。

## interrupt[i]

interrupt[i]的每个元素都相同，执行相同的汇编代码，这段汇编代码实际上很简单，它主要工作就是将**中断向量号**和**被中断上下文**(进程上下文或者中断上下文)保存到栈中，最后调用do_IRQ函数。
```c
# 代码地址:arch/x86/kernel/entry_32.S

# 开始
1:    pushl_cfi $(~vector+0x80)    /* Note: always in signed byte range */ # 先会执行这一句，将中断向量号取反然后加上0x80压入栈中
      .if ((vector-FIRST_EXTERNAL_VECTOR)%7) <> 6
    jmp 2f                                                     # 数字定义的标号为临时标号，可以任意重复定义，例如："2f"代表正向第一次出现的标号"2:"，3b代表反向第一次出现的标号"3:"
      .endif
      .previous                                             # .previous使汇编器返回到该自定义段之前的段进行汇编，则回到上面的数据段
    .long 1b                                                 # 在数据段中执行标号1的操作
      .section .entry.text, "ax"                             # 回到代码段
vector=vector+1 
    .endif 
  .endr
2:    jmp common_interrupt

common_interrupt:
    ASM_CLAC
    addl $-0x80,(%esp) # 此时栈顶是(~vector + 0x80)，这里再加上-0x80，实际就是中断向量号取反，用于区别系统调用，系统调用是正数，中断向量是负数
    SAVE_ALL                 # 保存现场，将寄存器值压入栈中
    TRACE_IRQS_OFF           # 关闭中断跟踪
    movl %esp,%eax           # 将栈指针保存到eax寄存器，供do_IRQ使用
    call do_IRQ              # 调用do_IRQ
    jmp ret_from_intr        # 跳转到ret_from_intr，进行中断返回的一些处理
ENDPROC(common_interrupt)
    CFI_ENDPROC
```

需要注意这里面有一个SAVE_ALL是用于保存用户态寄存器值的，在上面的文章中有提到CPU会自动保存原来特权级的段和栈到内核栈中，但是通用寄存器并不会保存，所以这里会有个SAVE_ALL来保存通用寄存器的值。所以当SAVE_ALL执行完后，所有的上下文都已经保存完毕，最后结果如下:
![](computer_system/图片/save_all.jpg)

```asm
.macro SAVE_ALL
	cld
	PUSH_GS
	pushl_cfi %fs
	/*CFI_REL_OFFSET fs, 0;*/
	pushl_cfi %es
	/*CFI_REL_OFFSET es, 0;*/
	pushl_cfi %ds
	/*CFI_REL_OFFSET ds, 0;*/
	pushl_cfi %eax
	CFI_REL_OFFSET eax, 0
	pushl_cfi %ebp
	CFI_REL_OFFSET ebp, 0
	pushl_cfi %edi
	CFI_REL_OFFSET edi, 0
	pushl_cfi %esi
	CFI_REL_OFFSET esi, 0
	pushl_cfi %edx
	CFI_REL_OFFSET edx, 0
	pushl_cfi %ecx
	CFI_REL_OFFSET ecx, 0
	pushl_cfi %ebx
	CFI_REL_OFFSET ebx, 0
	movl $(__USER_DS), %edx
	movl %edx, %ds
	movl %edx, %es
	movl $(__KERNEL_PERCPU), %edx
	movl %edx, %fs
	SET_KERNEL_GS %edx
.endm
```


## do_IRQ

这是中断处理的核心函数，来到这里时，系统已经做了两件事:

- 系统屏蔽了所有可屏蔽中断(清除了CPU的IF标志位，由CPU自动完成)
- 将中断向量号和所有寄存器值保存到内核栈中

在do_IRQ中，首先会添加硬中断计数器，此行为导致了中断期间禁止调度发送，此后会根据中断向量号从vector_irq[]数组中获取对应的中断号，并调用handle_irq()函数出来该中断号对应的中断出来例程。
![](computer_system/图片/中断处理过程.jpg)


```c
__visible unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
{
    /* 将栈顶地址保存到全局变量__irq_regs中，old_regs用于保存现在的__irq_regs值，这一行代码很重要，实现了嵌套中断情况下的现场保存与还原 */
    struct pt_regs *old_regs = set_irq_regs(regs);

    /* 获取中断向量号，因为中断向量号是以取反方式保存的，这里再次取反 */
    unsigned vector = ~regs->orig_ax;
    /* 中断向量号 */
    unsigned irq;

    /* 硬中断计数器增加，硬中断计数器保存在preempt_count */
    irq_enter();
    /* 这里开始禁止调度，因为preempt_count不为0 */

    /* 退出idle进程(如果当前进程是idle进程的情况下) */
    exit_idle();

    /* 根据中断向量号获取中断号 */
    irq = __this_cpu_read(vector_irq[vector]);

    /* 主要函数是handle_irq，进行中断服务例程的处理 */
    if (!handle_irq(irq, regs)) {
        /* EIO模式的应答 */
        ack_APIC_irq();

        /* 该中断号并没有发生过多次触发 */
        if (irq != VECTOR_RETRIGGERED) {
            pr_emerg_ratelimited("%s: %d.%d No irq handler for vector (irq %d)\n",
                         __func__, smp_processor_id(),
                         vector, irq);
        } else {
            /* 将此中断向量号对应的vector_irq设置为未定义 */
            __this_cpu_write(vector_irq[vector], VECTOR_UNDEFINED);
        }
    }
    /* 硬中断计数器减少 */
    irq_exit();
    /* 这里开始允许调度 */

    /* 恢复原来的__irq_regs值 */
    set_irq_regs(old_regs);
    return 1;
}
```

### handle_irq()
do_IRQ()函数中最重要的就是handle_irq()处理了，我们看看:
```c
bool handle_irq(unsigned irq, struct pt_regs *regs)
{
    struct irq_desc *desc;
    int overflow;

    /* 检查栈是否溢出 */
    overflow = check_stack_overflow();

    /* 获取中断描述符 */
    desc = irq_to_desc(irq);
    /* 检查是否获取到中断描述符 */
    if (unlikely(!desc))
        return false;

    /* 检查使用的栈，有两种情况，如果进程的内核栈配置为8K，则使用进程的内核栈，如果为4K，系统会专门为所有中断分配一个4K的栈专门用于硬中断处理栈，一个4K专门用于软中断处理栈，还有一个4K专门用于异常处理栈 */
    if (user_mode_vm(regs) || !execute_on_irq_stack(overflow, desc, irq)) {
        if (unlikely(overflow))
            print_stack_overflow();
        /* 执行handle_irq */
        desc->handle_irq(irq, desc);
    }

    return true;
}
```

#### irq_desc
![中断描述符](computer_system/中断和异常/中断和异常.md#中断描述符)


好的，最后执行中断描述符中的handle_irq指针所指函数，我们回忆一下，在初始化阶段，所有的中断描述符的handle_irq指针指向了handle_level_irq()函数，文章开头我们也说过，中断产生方式有两种：一种电平触发、一种是边沿触发。handle_level_irq()函数就是用于处理电平触发的情况，系统内建了一些handle_irq函数，具体定义在include/linux/irq.h文件中，上面的引用有所以及。

### handle_level_irq()
我们主要看看handle_level_irq()函数函数，因为触发方式不同，通知中断控制器、CPU屏蔽、中断状态设置的时机都不同，它们的代码都在kernel/irq/chip.c中。
```c
void
handle_level_irq(unsigned int irq, struct irq_desc *desc)
{
    raw_spin_lock(&desc->lock);
    /* 通知中断控制器屏蔽该中断线，并设置中断描述符屏蔽该中断 */
    mask_ack_irq(desc);

    /* 检查此irq是否处于运行状态，也就是检查IRQD_IRQ_INPROGRESS标志和IRQD_WAKEUP_ARMED标志。大家可以看看，还会检查poll */
    if (!irq_may_run(desc))
        goto out_unlock;

    desc->istate &= ~(IRQS_REPLAY | IRQS_WAITING);
    /* 增加此中断号所在proc中的中断次数 */
    kstat_incr_irqs_this_cpu(irq, desc);

    /*
     * If its disabled or no action available
     * keep it masked and get out of here
     */
    /* 判断IRQ是否有中断服务例程(irqaction)和是否被系统禁用 */
    if (unlikely(!desc->action || irqd_irq_disabled(&desc->irq_data))) {
        desc->istate |= IRQS_PENDING;
        goto out_unlock;
    }

    /* 在里面执行中断服务例程 */
    handle_irq_event(desc);
    /* 通知中断控制器恢复此中断线 */
    cond_unmask_irq(desc);

out_unlock:
    raw_spin_unlock(&desc->lock);
}
```

### handle_irq_event()

```c
irqreturn_t handle_irq_event(struct irq_desc *desc)
{
    struct irqaction *action = desc->action;
    irqreturn_t ret;

    desc->istate &= ~IRQS_PENDING;
    /* 设置该中断处理正在执行，设置此中断号的状态为IRQD_IRQ_INPROGRESS */
    irqd_set(&desc->irq_data, IRQD_IRQ_INPROGRESS);
    raw_spin_unlock(&desc->lock);

    /* 主要，具体看 */
    ret = handle_irq_event_percpu(desc, action);

    raw_spin_lock(&desc->lock);
    /* 取消此中断号的IRQD_IRQ_INPROGRESS状态 */
    irqd_clear(&desc->irq_data, IRQD_IRQ_INPROGRESS);
    return ret;
}
```

### handle_irq_event_percpu()

```c
irqreturn_t
handle_irq_event_percpu(struct irq_desc *desc, struct irqaction *action)
{
    irqreturn_t retval = IRQ_NONE;
    unsigned int flags = 0, irq = desc->irq_data.irq;

    /* desc中的action是一个链表，每个节点包含一个处理函数，这个循环是遍历一次action链表，分别执行一次它们的处理函数 */
    do {
        irqreturn_t res;

        /* 用于中断跟踪 */
        trace_irq_handler_entry(irq, action);
        /* 执行处理，在驱动中定义的中断处理最后就是被赋值到中断服务例程action的handler指针上，这里就执行了驱动中定义的中断处理 */
        res = action->handler(irq, action->dev_id);
        trace_irq_handler_exit(irq, action, res);

        if (WARN_ONCE(!irqs_disabled(),"irq %u handler %pF enabled interrupts\n",
                  irq, action->handler))
            local_irq_disable();

        /* 中断返回值处理 */
        switch (res) {
        /* 需要唤醒该中断处理例程的中断线程 */
        case IRQ_WAKE_THREAD:
            /*
             * Catch drivers which return WAKE_THREAD but
             * did not set up a thread function
             */
            /* 该中断服务例程没有中断线程 */
            if (unlikely(!action->thread_fn)) {
                warn_no_thread(irq, action);
                break;
            }
            /* 唤醒线程 */
            __irq_wake_thread(desc, action);

            /* Fall through to add to randomness */
        case IRQ_HANDLED:
            flags |= action->flags;
            break;

        default:
            break;
        }

        retval |= res;
        /* 下一个中断服务例程 */
        action = action->next;
    } while (action);

    add_interrupt_randomness(irq, flags);
    
    /* 中断调试会使用 */
    if (!noirqdebug)
        note_interrupt(irq, desc, retval);
    return retval;
}
```


其实代码上很简单，我们需要注意几个屏蔽中断的方式：**清除EFLAGS的IF标志、通知中断控制器屏蔽指定中断、设置中断描述符的状态为IRQD_IRQ_INPROGRESS**。在上述代码中这三种状态都使用到了，我们具体解释一下：

- **清除EFLAGS的IF标志：CPU禁止中断，当CPU进入到中断处理时自动会清除EFLAGS的IF标志，也就是进入中断处理时会自动禁止中断。在SMP系统中，就是单个CPU禁止中断。
- **通知中断控制器屏蔽指定中断：在中断控制器处就屏蔽中断，这样该中断产生后并不会发到CPU上。在SMP系统中，效果相当于所有CPU屏蔽了此中断。系统在执行此中断的中断处理函数才会要求中断控制器屏蔽该中断，所以没必要在此中断的处理过程中中断控制器再发一次中断信号给CPU。
- **设置中断描述符的状态为IRQD_IRQ_INPROGRESS：在SMP系统中，同一个中断信号有可能发往多个CPU，但是中断处理只应该处理一次，所以设置状态为IRQD_IRQ_INPROGRESS，其他CPU执行此中断时都会先检查此状态(可看handle_level_irq()函数)。

所以在SMP系统下，对于handle_level_irq而言，一次典型的情况是:中断控制器接收到中断信号，发送给一个或多个CPU，收到的CPU会自动禁止中断，并执行中断处理函数，在中断处理函数中CPU会通知中断控制器屏蔽该中断，之后当执行中断服务例程时会设置该中断描述符的状态为IRQD_IRQ_INPROGRESS，表明其他CPU如果执行该中断就直接退出，因为本CPU已经在处理了。


## 软中断

> 我们看到中断实际分为了两个部分，俗称就是一部分是**硬中断**，一部分是**软中断**。软中断是专门用于处理中断过程中费时费力的操作，而为什么系统要分硬中断和软中断呢？问得明白点就是为什么需要软中断。我们可以试着想想，如果只有硬中断的情况下，我们需要在中断处理过程中执行一些耗时的操作，比如浮点数运算，复杂算法的运算时，其他的外部中断就不能得到及时的响应，因为在硬中断过程中中断是关闭着的，甚至一些很紧急的中断会得不到响应，系统稳定性和及时性都受到很大影响。所以linux为了解决上述这种情况，将中断处理分为了两个部分，硬中断和软中断。首先一个外部中断得到响应时，会先关中断，并进入到硬中断完成较为紧急的操作，然后开中断，并在软中断执行那些非紧急、可延时执行的操作；在这种情况下，紧急操作可以立即执行，而其他的外部中断也可以获得一个较为快速的响应。这也是软中断存在的必要性。在软中断过程中是不可以被抢占也不能被阻塞的，也不能在一个给定的CPU上交错执行。

软中断是在中断框架中专门用于处理非紧急操作的，在SMP系统中，软中断可以并发地运行在多个CPU上，但在一些路径在需要使用自旋锁进行保护。在系统中，很多东西都分优先级，软中断也不例外，有些软中断要求更快速的响应运行，在内核中软中断一共分为10个，同时也代表着10种不同的优先级，系统用一个枚举变量表示：

```c
enum
{
    HI_SOFTIRQ=0,                     /* 高优先级tasklet */                              /* 优先级最高 */
    TIMER_SOFTIRQ,                    /* 时钟相关的软中断 */
    NET_TX_SOFTIRQ,                   /* 将数据包传送到网卡 */
    NET_RX_SOFTIRQ,                   /* 从网卡接收数据包 */
    BLOCK_SOFTIRQ,                    /* 块设备的软中断 */
    BLOCK_IOPOLL_SOFTIRQ,             /* 支持IO轮询的块设备软中断 */
    TASKLET_SOFTIRQ,                  /* 常规tasklet */
    SCHED_SOFTIRQ,                    /* 调度程序软中断 */
    HRTIMER_SOFTIRQ,                  /* 高精度计时器软中断 */
    RCU_SOFTIRQ,                      /* RCU锁软中断，该软中断总是最后一个软中断 */ 　　　　  /* 优先级最低 */

    NR_SOFTIRQS                       /* 软中断数，为10 */
};
```

注释中的tasklet我们之后会说明，这里先无视它。每一个优先级的软中断都使用一个struct softirq_action结构来表示，在这个结构中，只有一个成员变量，就是action函数指针，因为不同的软中断它的处理方式可能不同，从优先级表中就可以看出来，有块设备的，也有网卡处理的。系统将这10个软中断用softirq_vec[10]的数组进行保存。

```c
/* 用于描述一个软中断 */
struct softirq_action
{
    /* 此软中断的处理函数 */        
    void    (*action)(struct softirq_action *);
};

/* 10个软中断描述符都保存在此数组 */
static struct softirq_action softirq_vec[NR_SOFTIRQS] __cacheline_aligned_in_smp;
```

系统一般使用open_softirq()函数进行软中断描述符的初始化，主要就是将action函数指针指向该软中断应该执行的函数。在start_kernel()进行系统初始化中，就调用了softirq_init()函数对HI_SOFTIRQ和TASKLET_SOFTIRQ两个软中断进行了初始化:

```c
void __init softirq_init(void)
{
    int cpu;

    for_each_possible_cpu(cpu) {
        per_cpu(tasklet_vec, cpu).tail =
            &per_cpu(tasklet_vec, cpu).head;
        per_cpu(tasklet_hi_vec, cpu).tail =
            &per_cpu(tasklet_hi_vec, cpu).head;
    }

    /* 开启常规tasklet */
    open_softirq(TASKLET_SOFTIRQ, tasklet_action);
    /* 开启高优先级tasklet */
    open_softirq(HI_SOFTIRQ, tasklet_hi_action);
}

/* 开启软中断 */
void open_softirq(int nr, void (*action)(struct softirq_action *))
{
    softirq_vec[nr].action = action;
}
```

可以看到，TASKLET_SOFTIRQ的action操作使用了tasklet_action()函数，HI_SOFTIRQ的action操作使用了tasklet_hi_action()函数，这两个函数我们需要结合tasklet进行说明。我们也可以看看其他的软中断使用了什么函数：
```c
open_softirq(TIMER_SOFTIRQ, run_timer_softirq);
    open_softirq(NET_TX_SOFTIRQ, net_tx_action);
    open_softirq(NET_RX_SOFTIRQ, net_rx_action);
    open_softirq(BLOCK_SOFTIRQ, blk_done_softirq);
    open_softirq(BLOCK_IOPOLL_SOFTIRQ, blk_iopoll_softirq);
    open_softirq(SCHED_SOFTIRQ, run_rebalance_domains);
    open_softirq(HRTIMER_SOFTIRQ, run_hrtimer_softirq);
    open_softirq(RCU_SOFTIRQ, rcu_process_callbacks);
```

其实很明显可以看出，除了TASKLET_SOFTIRQ和HI_SOFTIRQ，其他的软中断更多地是用于特定的设备和环境，对于我们普通的IO驱动和设备而已，使用的软中断几乎都是TASKLET_SOFTIRQ和HI_SOFTIRQ，而系统为了对这些不同IO设备进行统一的处理，就在TASKLET_SOFTIRQ和HI_SOFTIRQ的action函数中使用到了tasklet。

　　对于每个CPU，都有一个irq_cpustat_t的数据结构，里面有一个__softirq_pending变量，这个变量很重要，用于表示该CPU的哪个软中断处于挂起状态，在软中断处理时可以根据此值跳过不需要处理的软中断，直接处理需要处理的软中断。内核使用local_softirq_pending()获取此CPU的__softirq_pending的值。

　　当使用open_softirq设置好某个软中断的action指针后，该软中断就会开始可以使用了，其实更明了地说，从中断初始化完成开始，即使所有的软中断都没有使用open_softirq()进行初始化，软中断都已经开始使用了，只是所有软中断的action都为空，系统每次执行到软中断都没有软中断需要执行罢了。

　　在每个CPU上一次软中断处理的一个典型流程是：

1. 硬中断执行完毕，开中断。
2. 检查该CPU是否处于嵌套中断的情况，如果处于嵌套中，则不执行软中断，也就是在最外层中断才执行软中断。
3. 执行软中断，设置一个软中断执行最多使用时间和循环次数(10次)。
4. 进入循环，获取CPU的__softirq_pending的副本。
5. 执行此__softirq_pending副本中所有需要执行的软中断。
6. 如果软中断执行完毕，退出中断上下文。
7. 如果还有软中断需要执行(在软中断期间又发发生了中断，产生了新的软中断，新的软中断记录在CPU的__softirq_pending上，而我们的__softirq_pending只是个副本)。
8. 检查此次软中断总共使用的时间和循环次数，条件允许继续执行软中断，循环次数减一，并跳转到第4步。

我们具体看一下代码，首先在irq_exit()中会检查是否需要进行软中断处理：
### irq_exit()


```c
void irq_exit(void)
{
#ifndef __ARCH_IRQ_EXIT_IRQS_DISABLED
    local_irq_disable();
#else
    WARN_ON_ONCE(!irqs_disabled());
#endif

    account_irq_exit_time(current);
    /* 减少preempt_count的硬中断计数器 */
    preempt_count_sub(HARDIRQ_OFFSET);
    
    /* in_interrupt()会检查preempt_count上的软中断计数器和硬中断计数器来判断是否处于中断嵌套中 */
    /* local_softirq_pending()则会检查该CPU的__softirq_pending变量，是否有软中断挂起 */
    if (!in_interrupt() && local_softirq_pending())
        invoke_softirq();

    tick_irq_exit();
    rcu_irq_exit();
    trace_hardirq_exit(); /* must be last! */
}
```

我们再进入到invoke_softirq():

### invoke_softirq()

```c
static inline void invoke_softirq(void)
{

    if (!force_irqthreads) {
#ifdef CONFIG_HAVE_IRQ_EXIT_ON_IRQ_STACK
        /*
         * We can safely execute softirq on the current stack if
         * it is the irq stack, because it should be near empty
         * at this stage.
         */
        /* 软中断处理函数 */
        __do_softirq();
#else
        /*
         * Otherwise, irq_exit() is called on the task stack that can
         * be potentially deep already. So call softirq in its own stack
         * to prevent from any overrun.
         */
        do_softirq_own_stack();
#endif
    } else {
        /* 如果强制使用软中断线程进行软中断处理，会通知调度器唤醒软中断线程ksoftirqd */
        wakeup_softirqd();
    }
}
```

重头戏就在__do_softirq()中:
### __do_softirq()

```c
asmlinkage __visible void __do_softirq(void)
{
    /* 为了防止软中断执行时间太长，设置了一个软中断结束时间 */
    unsigned long end = jiffies + MAX_SOFTIRQ_TIME;
    /* 保存当前进程的标志 */
    unsigned long old_flags = current->flags;
    /* 软中断循环执行次数: 10次 */
    int max_restart = MAX_SOFTIRQ_RESTART;
    /* 软中断的action指针 */
    struct softirq_action *h;
    bool in_hardirq;
    __u32 pending;
    int softirq_bit;

    /*
     * Mask out PF_MEMALLOC s current task context is borrowed for the
     * softirq. A softirq handled such as network RX might set PF_MEMALLOC
     * again if the socket is related to swap
     */
    current->flags &= ~PF_MEMALLOC;

    /* 获取此CPU的__softirq_pengding变量值 */
    pending = local_softirq_pending();
    /* 用于统计进程被软中断使用时间 */
    account_irq_enter_time(current);

    /* 增加preempt_count软中断计数器，也表明禁止了调度 */
    __local_bh_disable_ip(_RET_IP_, SOFTIRQ_OFFSET);
    in_hardirq = lockdep_softirq_start();

/* 循环10次的入口，每次循环都会把所有挂起需要执行的软中断执行一遍 */
restart:
    /* 该CPU的__softirq_pending清零，当前的__softirq_pending保存在pending变量中 */
    /* 这样做就保证了新的软中断会在下次循环中执行 */
    set_softirq_pending(0);

    /* 开中断 */
    local_irq_enable();

    /* h指向软中断数组头 */
    h = softirq_vec;

    /* 每次获取最高优先级的已挂起软中断 */
    while ((softirq_bit = ffs(pending))) {
        unsigned int vec_nr;
        int prev_count;
        /* 获取此软中断描述符地址 */
        h += softirq_bit - 1;

        /* 减去软中断描述符数组首地址，获得软中断号 */
        vec_nr = h - softirq_vec;
        /* 获取preempt_count的值 */
        prev_count = preempt_count();

        /* 增加统计中该软中断发生次数 */
        kstat_incr_softirqs_this_cpu(vec_nr);

        trace_softirq_entry(vec_nr);
        /* 执行该软中断的action操作 */
        h->action(h);
        trace_softirq_exit(vec_nr);

        /* 之前保存的preempt_count并不等于当前的preempt_count的情况处理，也是简单的把之前的复制到当前的preempt_count上，这样做是防止最后软中断计数不为0导致系统不能够执行调度 */
        if (unlikely(prev_count != preempt_count())) {
            pr_err("huh, entered softirq %u %s %p with preempt_count %08x, exited with %08x?\n",
                   vec_nr, softirq_to_name[vec_nr], h->action,
                   prev_count, preempt_count());
            preempt_count_set(prev_count);
        }
        /* h指向下一个软中断，但下个软中断并不一定需要执行，这里只是配合softirq_bit做到一个处理 */
        h++;
        pending >>= softirq_bit;
    }

    rcu_bh_qs();
    /* 关中断 */
    local_irq_disable();

    /* 循环结束后再次获取CPU的__softirq_pending变量，为了检查是否还有软中断未执行 */
    pending = local_softirq_pending();
    /* 还有软中断需要执行 */
    if (pending) {
        /* 在还有软中断需要执行的情况下，如果时间片没有执行完，并且循环次数也没到10次，继续执行软中断 */
        if (time_before(jiffies, end) && !need_resched() &&
            --max_restart)
            goto restart;
        /* 这里是有软中断挂起，但是软中断时间和循环次数已经用完，通知调度器唤醒软中断线程去执行挂起的软中断，软中断线程是ksoftirqd，这里只起到一个通知作用，因为在中断上下文中是禁止调度的 */
        wakeup_softirqd();
    }

    lockdep_softirq_end(in_hardirq);
    /* 用于统计进程被软中断使用时间 */
    account_irq_exit_time(current);
    /* 减少preempt_count中的软中断计数器 */
    __local_bh_enable(SOFTIRQ_OFFSET);
    WARN_ON_ONCE(in_interrupt());
    /* 还原进程标志 */
    tsk_restore_flags(current, old_flags, PF_MEMALLOC);
}
```

在目录 /kernel/softirq.c

### tasklet

软中断有多种，部分种类有自己特殊的处理，如从NET_TX_SOFTIRQ和NET_RT_SOFTIRQ、BLOCK_SOFTIRQ等，而如HI_SOFTIRQ和TASKLET_SOFTIRQ则是专门使用tasklet。它是在I/O驱动程序中实现可延迟函数的首选方法，如上一句所说，它建立在HI_SOFTIRQ和TASKLET_SOFTIRQ这两种软中断之上，多个tasklet可以与同一个软中断相关联，系统会使用一个链表组织他们，而每个tasklet执行自己的函数处理。而HI_SOFTIRQ和TASKLET_SOFTIRQ这两个软中断并没有什么区别，他们只是优先级上的不同而已，系统会先执行HI_SOFTIRQ的tasklet，再执行TASKLET_SOFTIRQ的tasklet。同一个tasklet不能同时在几个CPU上执行，一个tasklet在一个时间上只能在一个CPU的软中断链上，不能同时在多个CPU的软中断链上，并且当这个tasklet正在执行时，其他CPU不能够执行这个tasklet。也就是说，tasklet不必要编写成可重入的函数。

系统会为每个CPU维护两个链表，用于保存HI_SOFTIRQ的tasklet和TASKLET_SOFTIRQ的tasklet，这两个链表是tasklet_vec和tasklet_hi_vec，它们都是双向链表，如下：

```c
struct tasklet_head {
    struct tasklet_struct *head;
    struct tasklet_struct **tail;
};

static DEFINE_PER_CPU(struct tasklet_head, tasklet_vec);
static DEFINE_PER_CPU(struct tasklet_head, tasklet_hi_vec);
```

在softirq_init()函数中，会将每个CPU的tasklet_vec链表和tasklet_hi_vec链表进行初始化，将他们的头尾相连，实现为一个空链表。由于tasklet_vec和tasklet_hi_vec处理方式几乎一样，只是软中断的优先级别不同，我们只需要理解系统如何对tasklet_vec进行处理即可。需要注意的是，tasklet_vec链表都是以顺序方式执行，并不会出现后一个先执行，再到前一个先执行(在软中断期间被中断的情况)，之后的代码我们详细说明。

介绍完tasklet_vec和tasklet_hi_vec链表，我们来看看tasklet，tasklet简单来说，就是一个处理函数的封装，类似于硬中断中的irqaction结构。一般来说，在一个驱动中如果需要使用tasklet进行软中断的处理，只需要一个中断对应初始化一个tasklet，它可以在每次中断产生时重复使用。系统使用tasklet_struct结构进行描述一个tasklet，而且对于同一个tasklet_struct你可以选择放在tasklet_hi_vec链表或者tasklet_vec链表上。我们来看看：
```c
struct tasklet_struct
{
    struct tasklet_struct *next;      /* 指向链表下一个tasklet */
    unsigned long state;              /* tasklet状态 */
    atomic_t count;                   /* 禁止计数器，调用tasklet_disable()会增加此数，tasklet_enable()减少此数 */
    void (*func)(unsigned long);      /* 处理函数 */
    unsigned long data;               /* 处理函数使用的数据 */
};
```
tasklet状态主要分为以下两种：
- **TASKLET_STATE_SCHED:这种状态表示此tasklet处于某个tasklet链表之上(可能是tasklet_vec也可能是tasklet_hi_vec)。
- **TASKLET_STATE_RUN:表示此tasklet正在运行中。

这两个状态主要就是用于防止tasklet同时在几个CPU上运行和在同一个CPU上交错执行。

而func指针就是指向相应的处理函数。在编写驱动时，我们可以使用tasklet_init()函数或者DECLARE_TASKLET宏进行一个task_struct结构的初始化，之后可以使用tasklet_schedule()或者tasklet_hi_schedule()将其放到相应链表上等待CPU运行。我们使用一张图描述一下软中断和tasklet结合运行的情况：
![](computer_system/图片/tasklet.jpg)

我们知道，每个软中断都有自己的action函数，在HI_SOFTIRQ和TASKLET_SOFTIRQ的action函数中，就用到了它们对应的TASKLET_HI_VEC链表和TASKLET_VEC链表，并依次顺序执行链表中的每个tasklet结点。

在SMP系统中，我们会遇到一个问题：两个CPU都需要执行同一个tasklet的情况，虽然一个tasklet只能放在一个CPU的tasklet_vec链表或者tasklet_hi_vec链表上，但是这种情况是有可能发生的，我们设想一下，中断在CPU1上得到了响应，并且它的tasklet放到了CPU1的tasklet_vec上进行执行，而当中断的tasklet上正在执行时，此中断再次发生，并在CPU2上进行了响应，此时CPU2将此中断的tasklet放到CPU2的tasklet_vec上，并执行到此中断的tasklet。

实际上，为了处理这种情况，在HI_SOFTIRQ和TASKLET_SOFTIRQ的action函数中，会先将对应的tasklet链表取出来，并把对应的tasklet链表的head和tail清空，如果在执行过程中，某个tasklet的state为TASKLET_STATE_RUN状态，说明其他CPU正在处理这个tasklet，这时候当前CPU则会把此tasklet加入到当前CPU已清空的tasklet链表的末尾，然后设置__softirq_pending变量，这样，在下次循环软中断的过程中，会再次检查这个tasklet。也就是如果其他CPU的这个tasklet一直不退出，当前CPU就会不停的置位tasklet的pending，然后不停地循环检查。

我们可以看看TASKLET_SOFTIRQ的action处理：
```c
static void tasklet_action(struct softirq_action *a)
{
    struct tasklet_struct *list;

    local_irq_disable();
    /* 将tasklet链表从该CPU中拿出来 */
    list = __this_cpu_read(tasklet_vec.head);
    /* 将该CPU的此软中断的tasklet链表清空 */
    __this_cpu_write(tasklet_vec.head, NULL);
    __this_cpu_write(tasklet_vec.tail, this_cpu_ptr(&tasklet_vec.head));
    local_irq_enable();

    /* 链表已经处于list中，并且该CPU的tasklet_vec链表为空 */
    while (list) {
        struct tasklet_struct *t = list;

        list = list->next;

        /* 检查并设置该tasklet为TASKLET_STATE_RUN状态 */
        if (tasklet_trylock(t)) {
            /* 检查是否被禁止 */
            if (!atomic_read(&t->count)) {
                /* 清除其TASKLET_STATE_SCHED状态 */
                if (!test_and_clear_bit(TASKLET_STATE_SCHED,
                            &t->state))
                    BUG();
                /* 执行该tasklet的func处理函数 */
                t->func(t->data);
                /* 清除该tasklet的TASKLET_STATE_RUN状态 */
                tasklet_unlock(t);
                continue;
            }
            tasklet_unlock(t);
        }

        /* 以下为tasklet为TASKLET_STATE_RUN状态下的处理 */
        /* 禁止中断 */
        local_irq_disable();
        /* 将此tasklet添加的该CPU的tasklet_vec链表尾部 */
        t->next = NULL;
        *__this_cpu_read(tasklet_vec.tail) = t;
        __this_cpu_write(tasklet_vec.tail, &(t->next));
        /* 设置该CPU的此软中断处于挂起状态，设置irq_cpustat_t的__sofirq_pending变量，这样在软中断的下次执行中会再次执行此tasklet */
        __raise_softirq_irqoff(TASKLET_SOFTIRQ);
        /* 开启中断 */
        local_irq_enable();
    }
}
```


### 软中断处理线程

当有过多软中断需要处理时，为了保证进程能够得到一个满意的响应时间，设计时给定软中断一个时间片和循环次数，当时间片和循环次数到达但软中断又没有处理完时，就会把剩下的软中断交给软中断处理线程进行处理，这个线程是一个内核线程，其作为一个普通进程，优先级是120。其核心处理函数是run_ksoftirqd()，其实此线程的处理也很简单，就是调用了上面的__do_softirq()函数，我们可以具体看看：
```c
/* 在smpboot_thread_fun的一个死循环中被调用 */
static void run_ksoftirqd(unsigned int cpu)
{
    /* 禁止中断，在__do_softirq()中会开启 */
    local_irq_disable();
    /* 检查该CPU的__softirq_pending是否有软中断被挂起 */
    if (local_softirq_pending()) {
        /*
         * We can safely run softirq on inline stack, as we are not deep
         * in the task stack here.
         */
        /* 执行软中断 */
        __do_softirq();
        rcu_note_context_switch(cpu);
        /* 开中断 */
        local_irq_enable();
        /* 检查是否需要调度 */
        cond_resched();
        return;
    }
    /* 开中断 */
    local_irq_enable();
}
```