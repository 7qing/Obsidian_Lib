1. 进程与线程的区别
	**进程**是系统进行资源分配和调度的一个独立单位. **线程**是**进程**的一个实体,是CPU调度和分派的基本单位。
2. 父子进程
	共享含有程序代码的页，但是各自拥有独立的数据拷贝，因此子进程对一个内存单元的修改对父进程是不可见的（反之亦然）。
	写时复制技术允许读相同的物理页，只有两者之中的一个试图写一个物理页，内核就把这个页的内容拷贝到一个新的物理页，并把这个新的物理页分配给正在写的进程。

3. Linux下有3个特殊的进程，idle进程(PID = 0), init进程(PID = 1)和kthreadd(PID = 2)
	* idle进程由系统自动创建, 运行在内核态.idle进程其pid=0，其前身是系统创建的第一个进程，也是唯一一个没有通过fork或者kernel_thread产生的进程。完成加载系统后，演变为进程调度、交换。
	* init进程由idle通过kernel_thread创建，在内核空间完成初始化后, 加载init程序, 并最终用户空间由0进程创建，完成系统的初始化. 是系统中所有其它用户进程的祖先进程 .Linux中的所有进程都是有init进程创建并运行的。首先Linux内核启动，然后在用户空间中启动init进程，再启动其他系统进程。在系统启动完成完成后，init将变为守护进程监视系统其他进程。
	* kthread进程由idle通过kernel_thread创建，并始终运行在内核空间, 负责所有内核线程的调度和管理.它的任务就是管理和调度其他内核线程kernel_thread, 会循环执行一个kthread的函数，该函数的作用就是运行kthread_create_list全局链表中维护的kthread, 当我们调用kernel_thread创建的内核线程会被加入到此链表中，因此所有的内核线程都是直接或者间接的以kthreadd为父进程 。

## 进程描述符

这正是进程描述符(process descriptor)的作用---进程描述符都是task_struct类型结构,它的字段包含了与一个进程相关的所有信息。因为进程描述符中存放了那么多信息，所以它是相当复杂的。它不仅包含了很多进程属性的字段，而且一些字段还包括了指向其他数据结构的指针。

![](computer_system/图片/Linux进程描述符.png)

### 具体代码：

```
struct task_struct {
	volatile long state;	/* -1 unrunnable, 0 runnable, >0 stopped */
                            /* -1 表示不可运行，0 表示可运行，>0 表示已停止 */

	void *stack;            /* Pointer to the stack */
                            /* 指向栈的指针 */

	atomic_t usage;         /* Usage counter */
                            /* 使用计数器 */

	unsigned int flags;	/* Process flags */
                            /* 进程标志 */

	unsigned int ptrace;    /* Tracing flags */
                            /* 跟踪标志 */

	int lock_depth;         /* Lock depth for BKL */
                            /* 为BKL锁的深度 */

#ifdef CONFIG_SMP
#ifdef __ARCH_WANT_UNLOCKED_CTXSW
	int oncpu;              /* Which CPU is the task running on */
                            /* 任务正在哪个CPU上运行 */
#endif
#endif

	int prio, static_prio, normal_prio; /* Dynamic, static, and normal priorities */
                                        /* 动态优先级，静态优先级和普通优先级 */

	unsigned int rt_priority;           /* Real-time priority */
                                        /* 实时优先级 */

	const struct sched_class *sched_class; /* Scheduling class of the task */
                                            /* 任务的调度类 */

	struct sched_entity se;                  /* For CFS scheduling */
                                            /* 用于CFS调度 */

	struct sched_rt_entity rt;               /* For real-time scheduling */
                                            /* 用于实时调度 */

#ifdef CONFIG_PREEMPT_NOTIFIERS
	struct hlist_head preempt_notifiers;     /* List of preempt notifiers */
                                             /* 抢占通知器列表 */
#endif

	unsigned char fpu_counter;               /* FPU usage counter */
                                             /* FPU使用计数器 */

#ifdef CONFIG_BLK_DEV_IO_TRACE
	unsigned int btrace_seq;                 /* Block trace sequence */
                                             /* 块跟踪序列 */
#endif

	unsigned int policy;                     /* Scheduling policy */
                                             /* 调度策略 */

	cpumask_t cpus_allowed;                  /* CPUs allowed to run this task */
                                             /* 允许运行此任务的CPU */

#ifdef CONFIG_PREEMPT_RCU
	int rcu_read_lock_nesting;               /* Nesting level of RCU read-side critical sections */
                                             /* RCU读侧临界区的嵌套级别 */

	char rcu_read_unlock_special;            /* Special flags for RCU read-side */
                                             /* RCU读侧的特殊标志 */

	struct list_head rcu_node_entry;         /* RCU node entry */
                                             /* RCU节点条目 */
#endif

#ifdef CONFIG_TREE_PREEMPT_RCU
	struct rcu_node *rcu_blocked_node;       /* Pointer to blocked node in RCU */
                                             /* 指向RCU中被阻塞节点的指针 */
#endif

#ifdef CONFIG_RCU_BOOST
	struct rt_mutex *rcu_boost_mutex;        /* RT mutex for RCU boosting */
                                             /* 用于RCU增强的实时互斥锁 */
#endif

#if defined(CONFIG_SCHEDSTATS) || defined(CONFIG_TASK_DELAY_ACCT)
	struct sched_info sched_info;            /* Scheduler statistics */
                                             /* 调度器统计信息 */
#endif

	struct list_head tasks;                  /* List of tasks */
                                             /* 任务列表 */

#ifdef CONFIG_SMP
	struct plist_node pushable_tasks;        /* Tasks that are ready to run on any CPU */
                                             /* 准备在任何CPU上运行的任务 */
#endif

	struct mm_struct *mm, *active_mm;        /* Memory descriptors */
                                             /* 内存描述符 */

#ifdef CONFIG_COMPAT_BRK
	unsigned brk_randomized:1;               /* Is the brk space randomized? */
                                             /* brk空间是否随机化？ */
#endif

#if defined(SPLIT_RSS_COUNTING)
	struct task_rss_stat	rss_stat;         /* RSS stats */
                                             /* RSS统计 */
#endif

	int exit_state;                          /* Exit state of the task */
                                             /* 任务的退出状态 */

	int exit_code, exit_signal;              /* Exit code and signal */
                                             /* 退出代码和信号 */

	int pdeath_signal;                       /* Signal to send on parent death */
                                             /* 父进程死亡时发送的信号 */

	unsigned int personality;                /* Personality of the process */
                                             /* 进程的性格 */

	unsigned did_exec:1;                     /* Did an exec */
                                             /* 是否执行了exec */

	unsigned in_execve:1;                    /* Is in an execve syscall */
                                             /* 是否在execve系统调用中 */

	unsigned in_iowait:1;                    /* Is waiting on IO */
                                             /* 是否在等待IO */

	unsigned sched_reset_on_fork:1;          /* Reset scheduler params on fork */
                                             /* 在fork时重置调度器参数 */

	pid_t pid;                               /* Process ID */
                                             /* 进程ID */

	pid_t tgid;                              /* Thread group ID */
                                             /* 线程组ID */

#ifdef CONFIG_CC_STACKPROTECTOR
	unsigned long stack_canary;              /* Canary value for stack protection */
                                             /* 栈保护的金丝雀值 */
#endif

	struct task_struct *real_parent;         /* Real parent process */
                                                /* 实际父进程 */
	struct task_struct *parent;              /* Parent process */
                                                /* 父进程 */
	struct list_head children;               /* List of children */
                                                /* 子进程列表 */
	struct list_head sibling;                /* Sibling link */
                                                /* 兄弟进程链接 */
	struct task_struct *group_leader;        /* Leader of the process group */
                                                /* 进程组的领导进程 */

	struct list_head ptraced;                /* List of tasks this task is ptracing */
                                                /* 该任务正在ptrace的任务列表 */
	struct list_head ptrace_entry;           /* Entry for list of ptraced tasks */
                                                /* ptrace任务列表的入口 */

	struct pid_link pids[PIDTYPE_MAX];       /* Links for PID hash table */
                                                /* PID哈希表的链接 */
	struct list_head thread_group;           /* List of threads in the group */
                                                /* 组中线程的列表 */

	struct completion *vfork_done;           /* Completion for vfork */
                                                /* vfork完成情况 */
	int __user *set_child_tid;               /* Set child TID */
                                                /* 设置子线程的TID */
	int __user *clear_child_tid;             /* Clear child TID */
                                                /* 清除子线程的TID */

	cputime_t utime, stime;                  /* User and system CPU time */
                                                /* 用户态和系统态CPU时间 */
	cputime_t utimescaled, stimescaled;      /* Scaled user and system CPU time */
                                                /* 缩放的用户态和系统态CPU时间 */
	cputime_t gtime;                         /* Guest time */
                                                /* 客户操作系统时间 */
	unsigned long nvcsw, nivcsw;             /* Voluntary and involuntary context switches */
                                                /* 自愿和非自愿上下文切换 */
	struct timespec start_time;              /* Start time in monotonic clock */
                                                /* 单调时钟的开始时间 */
	struct timespec real_start_time;         /* Start time in wall clock */
                                                /* 墙钟的开始时间 */

	unsigned long min_flt, maj_flt;          /* Minor and major faults */
                                                /* 次要和主要错误 */

	struct task_cputime cputime_expires;     /* CPU time limits */
                                                /* CPU时间限制 */
	struct list_head cpu_timers[3];          /* CPU timers */
                                                /* CPU计时器 */

	const struct cred __rcu *real_cred;      /* Real credentials */
                                                /* 实际凭证 */
	const struct cred __rcu *cred;           /* Effective credentials */
                                                /* 有效凭证 */
	struct cred *replacement_session_keyring;/* Replacement session keyring */
                                                /* 替换会话密钥环 */

	char comm[TASK_COMM_LEN];                /* Command name */
                                                /* 命令名称 */

	int link_count, total_link_count;        /* Link counts for filesystems */
                                                /* 文件系统的链接计数 */

#ifdef CONFIG_SYSVIPC
	struct sysv_sem sysvsem;                 /* System V IPC semaphore */
                                                /* System V IPC信号量 */
#endif

#ifdef CONFIG_DETECT_HUNG_TASK
	unsigned long last_switch_count;         /* Last scheduler tick */
                                                /* 上一次调度器时钟 */
#endif

	struct thread_struct thread;             /* CPU-specific state */
                                                /* CPU特定状态 */
	struct fs_struct *fs;                    /* Filesystem information */
                                                /* 文件系统信息 */
	struct files_struct *files;              /* Open files */
                                                /* 打开的文件 */
	struct nsproxy *nsproxy;                 /* Namespace proxy */
                                                /* 命名空间代理 */
	struct signal_struct *signal;            /* Signal state */
                                                /* 信号状态 */
	struct sighand_struct *sighand;          /* Signal handlers */
                                                /* 信号处理程序 */

	sigset_t blocked, real_blocked;          /* Blocked signals */
                                                /* 阻塞信号 */
	sigset_t saved_sigmask;                  /* Saved signal mask */
                                                /* 保存的信号掩码 */
	struct sigpending pending;               /* Pending signals */
                                                /* 待处理的信号 */

	unsigned long sas_ss_sp;                 /* Stack segment pointer for set_altstack */
                                                /* 用于set_altstack的堆栈段指针 */
	size_t sas_ss_size;                      /* Stack segment size for set_altstack */
                                                /* 用于set_altstack的堆栈段大小 */

	int (*notifier)(void *priv);             /* Task notifier */
                                                /* 任务通知程序 */
	void *notifier_data;                     /* Notifier data */
                                                /* 通知程序数据 */
	sigset_t *notifier_mask;                 /* Notifier signal mask */
                                                /* 通知程序信号掩码 */
	struct audit_context *audit_context;     /* Audit context */
                                                /* 审计上下文 */

#ifdef CONFIG_AUDITSYSCALL
	uid_t loginuid;                          /* Login UID */
                                                /* 登录UID */
	unsigned int sessionid;                  /* Session ID */
                                                /* 会话ID */
#endif

	seccomp_t seccomp;                       /* Secure computing state */
                                                /* 安全计算状态 */

	u32 parent_exec_id;                      /* Parent execution ID */
                                                /* 父执行ID */
	u32 self_exec_id;                        /* Self execution ID */
                                                /* 自身执行ID */

	spinlock_t alloc_lock;                   /* Lock for resource allocation */
                                                /* 资源分配锁 */

#ifdef CONFIG_GENERIC_HARDIRQS
	struct irqaction *irqaction;             /* IRQ actions */
                                                /* IRQ操作 */
#endif

	raw_spinlock_t pi_lock;                  /* Lock for priority inheritance */
                                                /* 优先级继承锁 */

#ifdef CONFIG_RT_MUTEXES
	struct plist_head pi_waiters;            /* List of priority inheritance waiters */
                                                /* 优先级继承等待者列表 */
	struct rt_mutex_waiter *pi_blocked_on;   /* RT mutex this is blocked on */
                                                /* 阻塞于此的RT互斥体 */
#endif

#ifdef CONFIG_DEBUG_MUTEXES
	struct mutex_waiter *blocked_on;         /* Mutex this task is blocked on */
                                                /* 此任务阻塞的互斥体 */
#endif


#ifdef CONFIG_TRACE_IRQFLAGS
	unsigned int irq_events;                /* Number of IRQ events */
                                            /* IRQ事件的数量 */
	unsigned long hardirq_enable_ip;        /* IP where hard IRQs were enabled */
                                            /* 启用硬中断的位置（IP） */
	unsigned long hardirq_disable_ip;       /* IP where hard IRQs were disabled */
                                            /* 禁用硬中断的位置（IP） */
	unsigned int hardirq_enable_event;      /* Event count at hard IRQ enable */
                                            /* 启用硬中断时的事件计数 */
	unsigned int hardirq_disable_event;     /* Event count at hard IRQ disable */
                                            /* 禁用硬中断时的事件计数 */
	int hardirqs_enabled;                   /* Flag indicating if hard IRQs are enabled */
                                            /* 表示硬中断是否启用的标志 */
	int hardirq_context;                    /* Flag indicating if currently in hard IRQ context */
                                            /* 表示当前是否在硬中断上下文中的标志 */
	unsigned long softirq_disable_ip;       /* IP where soft IRQs were disabled */
                                            /* 禁用软中断的位置（IP） */
	unsigned long softirq_enable_ip;        /* IP where soft IRQs were enabled */
                                            /* 启用软中断的位置（IP） */
	unsigned int softirq_disable_event;     /* Event count at soft IRQ disable */
                                            /* 禁用软中断时的事件计数 */
	unsigned int softirq_enable_event;      /* Event count at soft IRQ enable */
                                            /* 启用软中断时的事件计数 */
	int softirqs_enabled;                   /* Flag indicating if soft IRQs are enabled */
                                            /* 表示软中断是否启用的标志 */
	int softirq_context;                    /* Flag indicating if currently in soft IRQ context */
                                            /* 表示当前是否在软中断上下文中的标志 */
#endif

#ifdef CONFIG_LOCKDEP
#define MAX_LOCK_DEPTH 48UL                 /* Maximum lock depth for lock dependency tracking */
                                            /* 锁依赖跟踪的最大锁深度 */
	u64 curr_chain_key;                     /* Current lock chain key */
                                            /* 当前锁链的键值 */
	int lockdep_depth;                      /* Current depth of lock dependency tracking */
                                            /* 当前锁依赖跟踪的深度 */
	unsigned int lockdep_recursion;         /* Flag to detect lockdep recursion */
                                            /* 检测锁依赖递归的标志 */
	struct held_lock held_locks[MAX_LOCK_DEPTH]; /* Array of held locks */
                                            /* 保存的锁的数组 */
	gfp_t lockdep_reclaim_gfp;              /* GFP flags for lockdep reclaim context */
                                            /* lockdep回收上下文的GFP标志 */
#endif

	void *journal_info;                     /* Pointer to journaling information */
                                            /* 指向日志信息的指针 */

	struct bio_list *bio_list;              /* List of block I/O bio structures */
                                            /* 块I/O bio结构的列表 */

#ifdef CONFIG_BLOCK
	struct blk_plug *plug;                  /* Pointer to blk_plug for stacking block device I/O */
                                            /* 指向用于堆叠块设备I/O的blk_plug的指针 */
#endif

	struct reclaim_state *reclaim_state;    /* Reclaim state for memory management */
                                            /* 内存管理的回收状态 */

	struct backing_dev_info *backing_dev_info; /* Information about backing device */
                                               /* 后备设备的信息 */

	struct io_context *io_context;          /* I/O context for asynchronous I/O */
                                            /* 异步I/O的I/O上下文 */

	unsigned long ptrace_message;           /* Message passed to tracer */
                                            /* 传递给跟踪器的消息 */

	siginfo_t *last_siginfo;                /* Last signal info, for ptrace */
                                            /* 最后的信号信息，用于ptrace */

	struct task_io_accounting ioac;         /* I/O accounting */
                                            /* I/O记账 */

#if defined(CONFIG_TASK_XACCT)
	u64 acct_rss_mem1;                      /* Accumulated resident set size memory usage */
                                            /* 累计的常驻集大小内存使用 */
	u64 acct_vm_mem1;                       /* Accumulated virtual memory usage */
                                            /* 累计的虚拟内存使用 */
	cputime_t acct_timexpd;                 /* Accumulated CPU time since last update */
                                            /* 自上次更新以来累计的CPU时间 */
#endif

#ifdef CONFIG_CPUSETS
	nodemask_t mems_allowed;               /* Memory nodes allowed for this task */
                                            /* 此任务允许的内存节点 */
	int mems_allowed_change_disable;       /* Flag to disable changing mems_allowed */
                                            /* 禁止更改mems_allowed的标志 */
	int cpuset_mem_spread_rotor;           /* Current node index for memory spread */
                                            /* 内存扩展的当前节点索引 */
	int cpuset_slab_spread_rotor;          /* Current node index for slab spread */
                                            /* Slab扩展的当前节点索引 */
#endif

#ifdef CONFIG_CGROUPS
	struct css_set __rcu *cgroups;          /* Control groups pointer */
                                            /* 控制组指针 */
	struct list_head cg_list;               /* List head for control group list */
                                            /* 控制组列表的列表头 */
#endif

#ifdef CONFIG_FUTEX
	struct robust_list_head __user *robust_list; /* List head for robust futexes */
                                                /* 健壮性futex的列表头 */
#ifdef CONFIG_COMPAT
	struct compat_robust_list_head __user *compat_robust_list; /* Compatibility list head for robust futexes */
                                                               /* 兼容性健壮性futex的列表头 */
#endif
	struct list_head pi_state_list;         /* List head for priority inheritance states */
                                            /* 优先级继承状态的列表头 */
	struct futex_pi_state *pi_state_cache;  /* Cached futex priority inheritance state */
                                            /* 缓存的futex优先级继承状态 */
#endif

#ifdef CONFIG_PERF_EVENTS
	struct perf_event_context *perf_event_ctxp[perf_nr_task_contexts]; /* Per-task performance event contexts */
                                                                       /* 每个任务的性能事件上下文 */
	struct mutex perf_event_mutex;           /* Mutex to protect performance event context */
                                            /* 保护性能事件上下文的互斥锁 */
	struct list_head perf_event_list;        /* List of performance events */
                                            /* 性能事件列表 */
#endif

#ifdef CONFIG_NUMA
	struct mempolicy *mempolicy;            /* Memory policy for NUMA */
                                            /* NUMA的内存策略 */
	short il_next;                          /* Next node index for interleaving */
                                            /* 交错的下一个节点索引 */
	short pref_node_fork;                   /* Preferred node for task fork */
                                            /* 任务分支的首选节点 */
#endif

	atomic_t fs_excl;                       /* Exclusive filesystem resources */
                                            /* 独占文件系统资源 */
	struct rcu_head rcu;                    /* RCU head used for call_rcu() */
                                            /* 用于call_rcu()的RCU头 */

	struct pipe_inode_info *splice_pipe;    /* Cached pipe for splice operations */
                                            /* 用于splice操作的缓存管道 */

#ifdef CONFIG_TASK_DELAY_ACCT
	struct task_delay_info *delays;         /* Delays accounting */
                                            /* 延迟记账 */
#endif

#ifdef CONFIG_FAULT_INJECTION
	int make_it_fail;                       /* Fault injection control */
                                            /* 故障注入控制 */
#endif

	struct prop_local_single dirties;       /* Dirty limits and statistics */
                                            /* 脏页限制和统计 */

#ifdef CONFIG_LATENCYTOP
	int latency_record_count;               /* Number of latency records */
                                            /* 延迟记录的数量 */
	struct latency_record latency_record[LT_SAVECOUNT]; /* Array of latency records */
                                                        /* 延迟记录数组 */
#endif

	unsigned long timer_slack_ns;           /* Timer slack in nanoseconds */
                                            /* 定时器的松弛时间（纳秒） */
	unsigned long default_timer_slack_ns;   /* Default timer slack in nanoseconds */
                                            /* 默认的定时器松弛时间（纳秒） */

	struct list_head *scm_work_list;        /* List of SCM work items */
                                            /* SCM工作项列表 */

#ifdef CONFIG_FUNCTION_GRAPH_TRACER
	int curr_ret_stack;                     /* Current index in the stack of function return addresses */
                                            /* 函数返回地址栈的当前索引 */
	struct ftrace_ret_stack *ret_stack;     /* Stack of return addresses for function tracing */
                                            /* 用于函数跟踪的返回地址栈 */
	unsigned long long ftrace_timestamp;    /* Timestamp for the last schedule in function graph tracing */
                                            /* 函数图跟踪中最后一次调度的时间戳 */
	atomic_t trace_overrun;                 /* Counter for trace buffer overruns, indicating the loss of trace data */
                                            /* 跟踪缓冲区溢出计数器，指示丢失的跟踪数据 */
	atomic_t tracing_graph_pause;           /* Atomic flag to pause/resume function graph tracing */
                                            /* 用于暂停/恢复函数图跟踪的原子标志 */
#endif



#ifdef CONFIG_TRACING
	/* state flags for use by tracers */
	unsigned long trace;                    /* Flags used by tracers to manage tracing states */
                                            /* 用于跟踪器管理跟踪状态的标志 */
	/* bitmask of trace recursion */
	unsigned long trace_recursion;          /* Bitmask to handle recursion in tracing */
                                            /* 处理跟踪递归的位掩码 */
#endif /* CONFIG_TRACING */

#ifdef CONFIG_CGROUP_MEM_RES_CTLR /* memcg uses this to do batch job */
	struct memcg_batch_info {
		int do_batch;	                    /* Incremented when batch uncharge is started */
                                            /* 批量未充电开始时递增 */
		struct mem_cgroup *memcg;           /* Target memory cgroup for uncharge */
                                            /* 未充电的目标内存组 */
		unsigned long nr_pages;	            /* Number of pages uncharged */
                                            /* 未充电的页面数 */
		unsigned long memsw_nr_pages;       /* Number of memory+swap pages uncharged */
                                            /* 未充电的内存+交换页面数 */
	} memcg_batch;
#endif

#ifdef CONFIG_HAVE_HW_BREAKPOINT
	atomic_t ptrace_bp_refcnt;              /* Reference count for hardware breakpoints */
                                            /* 硬件断点的引用计数 */
#endif

```


## 进程状态

进程状态由`volatile long state;`代码所定义，其中的state，我们在/include/linux/sched.h中有着以下的宏定义：
```
#define TASK_RUNNING		0
#define TASK_INTERRUPTIBLE	1
#define TASK_UNINTERRUPTIBLE	2
#define __TASK_STOPPED		4
#define __TASK_TRACED		8
/* in tsk->exit_state */
#define EXIT_ZOMBIE		16
#define EXIT_DEAD		32
/* in tsk->state again */
#define TASK_DEAD		64
#define TASK_WAKEKILL		128
#define TASK_WAKING		256
#define TASK_STATE_MAX		512
```

* 可运行状态(TASK_RUNNING)
	进程要么在CPU上执行，要么准备执行。可中断的等待状态(TASK_INTERRUPTIBLE)进程被挂起(睡眠)，直到某个条件变为真。产生一个硬件中断，释放进程正等待的系统资源，或传递一个信号都是可以唤醒进程的条件(把进程的状态放回到TASK_RUNNING)。
* 不可中断的等待状态(TASK_UNINTERRUPTIBLE)
	与可中断的等待状态类似,但有一个例外,把信号传递到睡眠进程不能改变它的状态。这种状态很少用到，但在一些特定的情况下(进程必须等待，直到一个不能被中断的事件发生)，这种状态是很有用的。例如，当进程打开一个设备文件，其相应的设备驱动程序开始探测相应的硬件设备时会用到这种状态。探测完成以前,设备驱动程序不能被中断，否则，硬件设备会处于不可预知的状态。
* 暂停状态(TASK_STOPPED)
	进程的执行被暂停。当进程接收到SIGSTOP、SIGTSTP、SIGTTIN或SIGTTOU信号后，进入暂停状态。
* 跟踪状态(TASK_TRACED)
	进程的执行已由debugger程序暂停。当一个进程被另一个进程监控时(例如debugger执行ptrace()系统调用监控一个测试程序)，任何信号都可以把这个进程置于 TASK_TRACED状态。

剩下两个进程状态是既可以存放在进程描述符的state字段中,也可以存放在exit_state字段中。从这两个字段的名称可以看出,只有当进程的执行被终止时,进程的状态才会变为这两种状态中的一种:

* 僵死状态(EXIT_2OMBIE)
	进程的执行被终止，但是，父进程还没有发布wait4()或waitpid()系统调用来返回有关死亡进程的信息。发布wait()类系统调用前，内核不能丢弃包含在死进程描述符中的数据，因为父进程可能还需要它。
* 僵死撤消状态(EXIT_DEAD)
	最终状态:由于父进程刚发出wait4()或waitpid()系统调用，因而进程由系统删除。为了防止其他执行线程在同一个进程上也执行wait()类系统调用(这是一种竞争条件)，而把进程的状态由僵死(EXIT_ZOMBIE)状态改为死撤消状态(EXIT_DEAD)。

![](computer_system/图片/process_schedule.jpg)
## 进程标识符（Process ID）

进程标识符（Process ID）是进程描述符中最重要的组成部分，是在当前 Linux 系统中唯一的一个非负整数，用于标识和对应唯一的进程。

在Linux中，有几个特殊的进程标识符所对应的进程。

* 进程标识符0：对应的是交换进程（swapper），用于执行多进程的调用。
* 进程标识符1：对应的是初始化进程（init），在自举过程结束时由内核调用，对应的文件是/sbin/init，负责 Linux 的启动工作，这个进程在系统运行过程中是不会终止的，可以说当前操作系统中的所有进程都是这个进程衍生而来的。
* 进程标识符2：可能对应页守护进程（pagedaemon），用于虚拟存储系统的分页操作。


```
#include <sys/types.h> 
#include <unistd.h> 
pid_t getpid(void); 
pid_t getppid(void);
```


由于循环使用PID编号，内核必须通过管理一个pidmap-array位图来表示当前已分配的PID号和闲置的PID号。因为一个页框包含32768个位，所以在32位体系结构中pidmap-array位图存放在一个单独的页中。然而，在64位体系结构中，当内核分配了超过当前位图大小的PID号时，需要为PID位图增加更多的页。系统会一直保存这些页不被释放。

对于pid的分配，是在[copy_process()]()过程中完成的：
```
static struct task_struct *copy_process(unsigned long clone_flags,
					unsigned long stack_start,
					struct pt_regs *regs,
					unsigned long stack_size,
					int __user *child_tidptr,
					struct pid *pid,
					int trace)
{
	struct task_struct *p;
	...
	if (pid != &init_struct_pid) {
		retval = -ENOMEM;
		pid = alloc_pid(p->nsproxy->pid_ns); // 分配pid
		if (!pid)
			goto bad_fork_cleanup_io;
	}

	p->pid = pid_nr(pid); //设置pid
	...
}
```

#### alloc_pid()

```
struct pid *alloc_pid(struct pid_namespace *ns)
{
	struct pid *pid;
	enum pid_type type;
	int i, nr;
	struct pid_namespace *tmp;
	struct upid *upid;

	pid = kmem_cache_alloc(ns->pid_cachep, GFP_KERNEL); //分配pid结构体的内存
	if (!pid)
		goto out;

	tmp = ns;
	for (i = ns->level; i >= 0; i--) {
		nr = alloc_pidmap(tmp); //分配pid
		if (nr < 0)
			goto out_free;

		pid->numbers[i].nr = nr; //nr保存到pid结构体
		pid->numbers[i].ns = tmp;
		tmp = tmp->parent;
	}

	get_pid_ns(ns);
	pid->level = ns->level;
	atomic_set(&pid->count, 1);
	for (type = 0; type < PIDTYPE_MAX; ++type)
		INIT_HLIST_HEAD(&pid->tasks[type]); //初始化pid的hlist结构体

	upid = pid->numbers + ns->level;
	spin_lock_irq(&pidmap_lock);
	for ( ; upid >= pid->numbers; --upid)
		hlist_add_head_rcu(&upid->pid_chain,
				&pid_hash[pid_hashfn(upid->nr, upid->ns)]); //建立pid_hash的关联关系
	spin_unlock_irq(&pidmap_lock);

out:
	return pid;

out_free:
	while (++i <= ns->level)
		free_pidmap(pid->numbers + i);

	kmem_cache_free(ns->pid_cachep, pid);
	pid = NULL;
	goto out;
}
```

我们来分析几个比较重要的地方：
##### `kmem_cache_alloc(ns->pid_cachep, GFP_KERNEL);`
1. **`kmem_cache_alloc`**：
    - 这是内核中用于分配内存的函数，它从特定的内核缓存中分配对象。内核通过这种方法来提高分配效率，并减少内存碎片。
    - 这里用 `kmem_cache_alloc` 从 PID 缓存中分配一个新的 `pid` 结构。
    - 内核使用对象缓存（[slab 缓存]()）来存储固定大小的对象（如 `pid` 结构）。通过这种机制，可以避免频繁的通用内存分配带来的性能损耗，同时减少内存碎片化。
1. **`ns->pid_cachep`**：
    - `pid_cachep` 是当前命名空间 ([namespace](#pid_namespace结构体)) 中用于管理 PID 的缓存指针。每个命名空间都有自己独立的 PID 缓存，用于存储与 PID 相关的数据。
1. **`GFP_KERNEL`**：
    - 这是分配标志，表示分配是在内核上下文中执行的，允许内存分配时进行阻塞等待。这是内核中最常用的分配模式。
2. **`pid`**：
    - `pid` 是一个变量，用于保存分配到的 `pid` 结构（进程标识符结构）。

##### `alloc_pidmap(tmp)`

```
static int alloc_pidmap(struct pid_namespace *pid_ns)
{
  //last_pid为上次分配出去的pid
  int i, offset, max_scan, pid, last = pid_ns->last_pid;
  struct pidmap *map;

  pid = last + 1;
  if (pid >= pid_max)
    pid = RESERVED_PIDS; //默认为300
    
  offset = pid & BITS_PER_PAGE_MASK; //最高位值置0，其余位不变
  map = &pid_ns->pidmap[pid/BITS_PER_PAGE]; //找到目标pidmap

  //当offset =0，则扫描一次;
  //当offset!=0，则扫描两次
  max_scan = DIV_ROUND_UP(pid_max, BITS_PER_PAGE) - !offset;
  for (i = 0; i <= max_scan; ++i) {
    if (unlikely(!map->page)) {
      void *page = kzalloc(PAGE_SIZE, GFP_KERNEL);
      spin_lock_irq(&pidmap_lock);
      if (!map->page) {
        map->page = page;
        page = NULL;
      }
      spin_unlock_irq(&pidmap_lock);
      kfree(page);
      if (unlikely(!map->page))
        break;
    }
    
    //当pidmap还有可用pid时
    if (likely(atomic_read(&map->nr_free))) {
      do {
        //当offset位空闲时返回该pid
        if (!test_and_set_bit(offset, map->page)) {
          atomic_dec(&map->nr_free); //可用pid减一
          set_last_pid(pid_ns, last, pid); //设置last_pid
          return pid;
        }
        //否则，查询下一个非0的offset值
        offset = find_next_offset(map, offset);
        根据offset转换成相应的pid
        pid = mk_pid(pid_ns, map, offset);
      } while (offset < BITS_PER_PAGE && pid < pid_max);
    }
    
    //当上述pid分配失败，则再次查找offset
    if (map < &pid_ns->pidmap[(pid_max-1)/BITS_PER_PAGE]) {
      ++map;
      offset = 0;
    } else {
      map = &pid_ns->pidmap[0];
      offset = RESERVED_PIDS;
      if (unlikely(last == offset))
        break;
    }
    pid = mk_pid(pid_ns, map, offset);
  }
  return -1;
}
```
##### `pid_namespace结构体`

```
struct pid_namespace {
  struct kref kref;  
  /* 引用计数，用于管理 `pid_namespace` 的生命周期。通过 kref 机制，
     当引用计数减为 0 时，`pid_namespace` 会被释放。 */

  struct pidmap pidmap[PIDMAP_ENTRIES];  
  /* PID 位图数组，每个 pidmap 用于标记哪些 PID 是空闲的，
     哪些已被分配。位图是用来高效管理 PID 分配的核心数据结构。 */

  struct rcu_head rcu;  
  /* 用于 RCU（Read-Copy Update）机制，当 `pid_namespace` 被释放时，
     确保在延迟删除期间不会破坏并发访问。 */

  int last_pid;  
  /* 最近一次分配的 PID。这个字段用于生成下一个 PID（从上次分配的 PID 开始递增）。 */

  unsigned int nr_hashed;  
  /* 当前命名空间中被分配 PID 的数量。这个值反映了命名空间中活动进程的数量。 */

  struct task_struct *child_reaper;  
  /* 指向该命名空间中充当 `init` 进程的任务结构指针。
     如果命名空间中没有任务存活，`child_reaper` 会负责回收孤儿进程。 */

  struct kmem_cache *pid_cachep;  
  /* Slab 缓存，用于快速分配和回收 `pid` 结构体对象，
     减少内存分配的开销和碎片化。 */

  unsigned int level;  
  /* 命名空间的嵌套级别，`0` 表示初始命名空间，数字越大表示嵌套越深。 */

  struct pid_namespace *parent;  
  /* 指向父命名空间。如果是初始命名空间（最顶层），则为 NULL。 */

  // 省略部分字段 ...

  struct user_namespace *user_ns;  
  /* 与当前 `pid_namespace` 相关联的用户命名空间。
     用户命名空间定义了与权限和 UID/GID 有关的隔离。 */

  struct work_struct proc_work;  
  /* 用于延迟执行操作的 `work_struct` 结构体，
     主要和 `/proc` 文件系统的相关操作有关。 */

  kgid_t pid_gid;  
  /* PID 的组 ID，决定了 `/proc` 文件系统中 `pid` 的所有者组权限。 */

  int hide_pid;  
  /* 决定是否隐藏进程信息：
     - 0：所有用户均可查看其他进程的信息。
     - 1：仅允许用户查看与自己相关的进程。
     - 2：完全隐藏其他用户的进程信息。 */

  int reboot;  
  /* 用于存储命名空间是否允许重启操作。 */

  struct ns_common ns;  
  /* 通用命名空间结构，提供与内核命名空间接口相关的字段（如 `inum`）。 */
};

```

PID命名空间，这是为系统提供虚拟化做支撑的功能。

## thread_info

Linux通过slab动态生成task_struct，那么在栈顶或栈底创建新的结构体thread_info即可，其中task指向其真正的task_struct结构体。

```
struct thread_info {
	struct task_struct	*task;		//主要的进程描述符
	struct exec_domain	*exec_domain;
	__u32			flags;		
	__u32			status;		// 线程同步flags
	__u32			cpu;		//当前cpu
	int			preempt_count;
	mm_segment_t		addr_limit;
	struct restart_block    restart_block;
	void __user		*sysenter_return;
	unsigned int		sig_on_uaccess_error:1;
	unsigned int		uaccess_err:1;
};
```

### 内核stack和thread_info结构的关系

```
union thread_union {
    struct thread_info thread_info;
    unsigned long stack[THREAD_SIZE/sizeof(long)];
};
 
#define THREAD_SIZE        16384 \\8k
#define THREAD_START_SP        (THREAD_SIZE - 16)
```

内核定义了一个thread_union的联合体，联合体的作用就是thread_info和stack共用一块内存区域。

![](computer_system/图片/thread_info与内核栈的关系.png)

我们获得当前内核栈的sp指针的地址，然后根据THREAD_SIZE对齐就可以获取thread_info结构的基地址，然后从thread_info.task就可以获取当前task_struct结构的地址了。

```
#define get_current() (current_thread_info()->task)
#define current get_current()
 
/*
 * how to get the current stack pointer from C
 */
register unsigned long current_stack_pointer asm ("sp");
 
/*
 * how to get the thread information struct from C
 */
static inline struct thread_info *current_thread_info(void) __attribute_const__;
 
static inline struct thread_info *current_thread_info(void)
{
    return (struct thread_info *)
        (current_stack_pointer & ~(THREAD_SIZE - 1));
}
```


## 进程切换

### 硬件上下文

我们知道每个进程都有自己的地址空间，但是所有的进程却共享CPU寄存器。所以，在恢复进程执行之前，内核必须保证该进程在挂起时的寄存器值重新加载到CPU的寄存器中。

这些需要加载到CPU寄存器中的值就成为硬件上下文。硬件上下文是进程执行上下文的一个子集，进程执行上下文包含进程执行所需要的所有信息。在Linux中，进程的硬件上下文一部分存储在进程描述符中，而其它部分存储在内核态的栈中。

在下面的描述中，我们假设，prev指向旧进程，而next指向新进程。因此，我们就可以说，进程切换就是保存prev进程的硬件上下文，然后加载next进程的硬件上下文。因为进程的切换非常频繁，所以缩短保存和加载硬件上下文的时间就很重要了。

硬件上下文放在 task_struct 中的 thread（struct thread_struct）中的struct cpu_context中（arm64），但在x8664中又有所不同。我们来解析一下struct thread_struct：

#### struct thread_struct

```
struct thread_struct {
	/* TLS（线程本地存储）相关： */
	struct desc_struct	tls_array[GDT_ENTRY_TLS_ENTRIES];
	/* 每个线程可以有多个 TLS 段（最多3个，分别为 FS、GS 和 DS 段），
	   这些段用于实现线程本地存储，在多线程环境下用于隔离数据访问。 */

#ifdef CONFIG_X86_32
	unsigned long		sp0;
	/* 用户态线程切换到内核态时的栈指针，专用于 x86_32 架构。 */
#endif

	unsigned long		sp;
	/* 当前栈指针，保存当前线程的栈位置（用户态或内核态）。 */

#ifdef CONFIG_X86_32
	unsigned long		sysenter_cs;
	/* 在 x86_32 架构中，保存 `SYSENTER` 指令的代码段选择子，用于快速系统调用。 */
#else
	unsigned short		es;
	unsigned short		ds;
	unsigned short		fsindex;
	unsigned short		gsindex;
	/* 在 x86_64 架构中，保存段寄存器选择子。FS 和 GS 常用于线程本地存储。 */
#endif

#ifdef CONFIG_X86_64
	unsigned long		fsbase;
	unsigned long		gsbase;
	/* 在 x86_64 架构中，FS 和 GS 寄存器的基址。
	   这些值通常用于实现线程本地存储（TLS）。 */
#else
	unsigned long fs;
	unsigned long gs;
	/* 在 x86_32 架构中，FS 和 GS 的段选择子或基址。 */
#endif

	/* Ptrace 调试相关状态： */
	struct perf_event	*ptrace_bps[HBP_NUM];
	/* 硬件断点的状态，用于 ptrace 调试时保存断点的相关信息。 */

	unsigned long           debugreg6;
	/* 调试寄存器 DR6 的值，用于捕获硬件断点或调试事件。 */

	unsigned long           ptrace_dr7;
	/* 调试寄存器 DR7 的值，保存用户设置的调试状态。 */

	/* 故障相关信息： */
	unsigned long		cr2;
	/* 保存最近一次页错误的地址（由 CR2 寄存器提供）。 */
	unsigned long		trap_nr;
	/* 保存最近一次触发的异常号（Trap Number）。 */
	unsigned long		error_code;
	/* 保存最近一次异常的错误码（由硬件提供）。 */

#ifdef CONFIG_VM86
	/* 虚拟 8086 模式相关信息（仅适用于 x86）： */
	struct vm86		*vm86;
	/* 当线程运行在虚拟 8086 模式下时，指向与虚拟 8086 模式相关的状态信息。 */
#endif

	/* IO 端口访问相关： */
	unsigned long		*io_bitmap_ptr;
	/* 指向 IO 权限位图，用于限制线程对 IO 端口的访问权限。 */
	unsigned long		iopl;
	/* 当前线程的 IO 优先级级别（0-3，越低权限越高）。 */
	unsigned		io_bitmap_max;
	/* IO 位图中最大的允许端口号（以字节为单位）。 */

	/* 地址空间限制： */
	mm_segment_t		addr_limit;
	/* 当前线程的地址空间限制（`USER_DS` 或 `KERNEL_DS`），
	   决定线程是否运行在用户态还是内核态。 */

	/* 用户空间访问错误状态： */
	unsigned int		sig_on_uaccess_err:1;
	/* 如果用户态访问失败时，是否需要发送信号。 */
	unsigned int		uaccess_err:1;
	/* 线程最近一次用户空间访问是否失败的标志。 */

	/* 浮点和扩展处理器状态： */
	struct fpu		fpu;
	/* 保存线程的浮点运算单元（FPU）和扩展处理器状态（如 AVX、SSE）。 */

	/*
	 * WARNING: 'fpu' is dynamically-sized.  It *MUST* be at
	 * the end.
	 */
	/* 注意：`fpu` 是动态大小的结构体，必须放在结构体末尾以便动态扩展。 */
};
```

#### struct pt_regs

```
struct pt_regs {
/*
 * C ABI says these regs are callee-preserved. They aren't saved on kernel entry
 * unless syscall needs a complete, fully filled "struct pt_regs".
 */
	unsigned long r15;
	unsigned long r14;
	unsigned long r13;
	unsigned long r12;
	unsigned long bp;
	unsigned long bx;
/* These regs are callee-clobbered. Always saved on kernel entry. */
	unsigned long r11;
	unsigned long r10;
	unsigned long r9;
	unsigned long r8;
	unsigned long ax;
	unsigned long cx;
	unsigned long dx;
	unsigned long si;
	unsigned long di;
/*
 * On syscall entry, this is syscall#. On CPU exception, this is error code.
 * On hw interrupt, it's IRQ number:
 */
	unsigned long orig_ax;
/* Return frame for iretq */
	unsigned long ip;
	unsigned long cs;
	unsigned long flags;
	unsigned long sp;
	unsigned long ss;
/* top of stack page */
};
```


####  **`struct thread_struct`**
- 保存线程特定的架构相关状态，如：
    - `sp`（栈指针）、`addr_limit`（地址空间限制）。
    - FPU 状态和调试寄存器。
####  **`struct pt_regs`**

- 保存中断或异常发生时的寄存器状态。
####  **`task_struct`**

- 包含线程的所有上下文信息，包括 `thread_struct` 和调度信息.

####  **`struct fpu`**

- 保存线程的浮点处理单元（FPU）和扩展寄存器状态。

#### 新旧方法：
旧版本的linux利用x86架构提供的硬件支持，并通过远程调转指令（GNU-`ljump`；Intel-`jmp far`）进行进程切换，跳转到下一个进程的任务状态段（TSS）描述符。执行这条跳转指令的同时，CPU自动执行硬件上下文切换，保存旧的硬件上下文，加载新的硬件上下文。但是，linux2.6版本以后，通过软件进行进程切换，原因如下：

- 通过一连串的mov指令，一步步执行切换，可以更好地控制加载数据的合法性。尤其是ds和es段寄存器中的值，有可能会被恶意用户篡改。如果使用远程跳转指令是无法进程数据检查的。
- 新旧方法所要求的时间是大致相同的。但是，优化硬件上下文的切换是不可能的，因为都是由CPU完成的，而Linux是使用软件代替硬件上下文切换的，所以有优化的空间，以便提高执行时间。
### 任务状态段-TSS

x86架构包含一个特殊的段寄存器，称为任务状态段（TSS），用来保存硬件上下文内容。尽管Linux不使用硬件上下文切换，但还是给每个不同CPU建立一个TSS。这么做，基于两个原因：

- 当x86架构的CPU从用户态到内核态时，会从TSS中获取内核态的栈地址
- 用户态进程想要访问I/O端口的时候，CPU需要访问存储在TSS中的I/O权限位，判断进程是否被允许访问这个I/O端口。那么，当用户态进程执行in或out指令时，I/O控制单元到底做了什么呢？
    1. 检查eflags寄存器中IOPL位（2位）。如果等于3，也就是超级用户权限，也就是进程对于这个I/O端口来说就是一个超级用户，那么，直接执行I/O指令。否则，继续执行检查。
    2. 访问tr寄存器，确定当前的TSS，以及正确的I/O访问权限。
    3. 它检查I/O端口对应的访问权限位。如果清零，指令被执行；否则，控制单元发出常规保护的异常。

内核中使用tss_struct结构体描述TSS。init_tss数组为系统中的每一个CPU包含一个tss_struct结构。每一次进程切换，内核更新TSS相关内容，使CPU控制单元能够安全地检索自己想要的信息。因而，TSS反映了当前运行在CPU上的进程的特权级别，但是当进程不运行的时候，无需维护这些信息。

```c
struct tss_struct {  
/*  
* The fixed hardware portion. This must not cross a page boundary  
* at risk of violating the SDM's advice and potentially triggering  
* errata.  
*/  
struct x86_hw_tss x86_tss;

/*
 * The extra 1 is there because the CPU will access an
 * additional byte beyond the end of the IO permission
 * bitmap. The extra byte must be all 1 bits, and must
 * be within the limit.
 */
unsigned long		io_bitmap[IO_BITMAP_LONGS + 1];
} __aligned(PAGE_SIZE);
```

#### **结构分析**

##### **(1) `struct x86_hw_tss`**

这个字段是 TSS 的“硬件部分”，它是由 CPU 硬件定义并由操作系统使用的。主要内容如下：

- **`struct x86_hw_tss` 的组成**：
    
    - **ESP0**（堆栈指针 0）：指向内核态堆栈（在系统调用或中断时从用户态切换到内核态时使用）。
    - **SS0**（堆栈段 0）：配合 ESP0 指向内核态堆栈。
    - **IO Map Base**（I/O 位图基地址）：用于控制对 I/O 端口的访问。
    - 其他与段寄存器、特权级、调试相关的字段。
    
    在 x86_64 上，TSS 中的很多字段已经废弃，堆栈切换（ESP0）和 IO 位图是其最主要的用途。

##### **(2) `io_bitmap`**
- **I/O 权限位图（IO Permission Bitmap）**：
    - 控制任务或线程对 I/O 端口的访问。
    - 如果某个线程试图访问未授权的 I/O 端口，CPU 会触发一个异常。
    - 在 Linux 中，`io_bitmap` 很少使用，大多数任务对所有 I/O 端口都没有直接访问权限。
- **为何有额外的 1 字节**：
    - 根据 x86 的规范，CPU 在访问 I/O 位图时，会多读取一个额外的字节。
    - 为了保证安全性，位图的额外字节必须设置为全 1（禁用访问），同时位图需要在限制范围内。


### 进程切换的一般过程

（1）正在运行的用户态进程X  
（2）发生中断——save cs:eip/esp/eflags(current) to kernel stack,then load cs:eip(entry of a specific ISR) and ss:esp(point to kernel stack).  
（3）SAVE_ALL //保存现场  
（4）中断处理过程中或中断返回前调用了schedule()，其中的switch_to做了关键的进程上下文切换  
（5） 标号1之后开始运行用户态进程Y(这里Y曾经通过以上步骤被切换出去过因此可以从标号1继续执行)  
（6） restore_all //恢复现场  
（7）iret - pop cs:eip/ss:esp/eflags from kernel stack  
（8）继续运行用户态进程Y

### 进程切换源码结构

![](/computer_system/图片/进程切换.png)

我们只需要关注几个比较重要的地方：

- 首先，schedule()函数会调用`next = pick_next_task(rq, prev);`，所做的工作就是根据调度算法策略，选取要执行的下一个进程。
- 其次，根据调度策略得到要执行的进程后，调用`context_switch(rq, prev, next);`，完成进程上下文切换。然后，调用`cppswitch_mm_irqs_off`  ,完成进程地址空间切换。其中，最关键的`switch_to(prev,next, prev);`切换堆栈和寄存器的状态。

### switch_to宏

进程硬件上下文的切换是由宏`switch_to`完成的。该宏的实现与硬件架构是息息相关的，要想理解它需要下一番功夫。switch_to是通过内联汇编操作的，在调试过程中无法进入，只能进入__switch_to函数。下面是基于X86架构下的该宏实现的汇编代码：

```c
#define switch_to(prev, next, last)					\
do {									\
	/*								\
	 * Context-switching clobbers all registers, so we clobber	\
	 * them explicitly, via unused output variables.		\
	 * (EAX and EBP is not listed because EBP is saved/restored	\
	 * explicitly for wchan access and EAX is the return value of	\
	 * __switch_to())						\
	 */								\
	unsigned long ebx, ecx, edx, esi, edi;				\
									\
	asm volatile("pushfl\n\t"		/* save    flags */	\
		     "pushl %%ebp\n\t"		/* save    EBP   */	\//保存当前进程的栈基址
		     "movl %%esp,%[prev_sp]\n\t"	/* save    ESP   */ \//保存当前的栈顶
		     "movl %[next_sp],%%esp\n\t"	/* restore ESP   */ \//这里实现内核堆栈的切换
		     "movl $1f,%[prev_ip]\n\t"	/* save    EIP   */	\
			//保存当前进程的EIP，next_ip一般是$1f，对于新创建的子进程是ret_from_fork
		     "pushl %[next_ip]\n\t"	/* restore EIP   */	\//将下一个进程的起始位置压栈
		     __switch_canary					\
		     "jmp __switch_to\n"	/* regparm call  */	\//通过寄存器传参数，返回1f位置
		     "1:\t"						\
		     "popl %%ebp\n\t"		/* restore EBP   */	\//弹出之前被调度时的ebp
		     "popfl\n"			/* restore flags */	\
									\
		     /* output parameters */				\
		     : [prev_sp] "=m" (prev->thread.sp),		\//保存当前进程的esp
		       [prev_ip] "=m" (prev->thread.ip),		\//保存当前进程的eip
		       "=a" (last),					\
									\
		       /* clobbered output registers: */		\
		       "=b" (ebx), "=c" (ecx), "=d" (edx),		\
		       "=S" (esi), "=D" (edi)				\
		       							\
		       __switch_canary_oparam				\
									\
		       /* input parameters: */				\
		     : [next_sp]  "m" (next->thread.sp),		\
		       [next_ip]  "m" (next->thread.ip),		\
		       							\
		       /* regparm parameters for __switch_to(): */	\
		       [prev]     "a" (prev),				\
		       [next]     "d" (next)				\
									\
		       __switch_canary_iparam				\
									\
		     : /* reloaded segment registers */			\
			"memory");					\
} while (0)
```